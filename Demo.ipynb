{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Demo.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q2hhyBh74BRa",
        "outputId": "4cb155b2-4ec6-449a-fccf-2eeb6961a436"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mon Jan 25 14:08:51 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   34C    P8    27W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mGewvH62sBv_",
        "outputId": "c639890d-9083-4f99-90e0-4cc64cb94169"
      },
      "source": [
        "!git clone https://github.com/polakowo/gpt2bot.git temp\n",
        "!cp -r temp/* .\n",
        "!rm -rf temp"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'temp'...\n",
            "remote: Enumerating objects: 188, done.\u001b[K\n",
            "remote: Counting objects: 100% (188/188), done.\u001b[K\n",
            "remote: Compressing objects: 100% (124/124), done.\u001b[K\n",
            "remote: Total 547 (delta 122), reused 124 (delta 63), pack-reused 359\u001b[K\n",
            "Receiving objects: 100% (547/547), 5.69 MiB | 1.82 MiB/s, done.\n",
            "Resolving deltas: 100% (335/335), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YHPZ74autU_R",
        "outputId": "9a49d36c-931e-4495-a681-e605072c7d40"
      },
      "source": [
        "!pip install -r requirements.txt"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow>=2.4.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 1)) (2.4.0)\n",
            "Requirement already satisfied: torch>=1.7.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 2)) (1.7.0+cu101)\n",
            "Collecting transformers>=4.2.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/88/b1/41130a228dd656a1a31ba281598a968320283f48d42782845f6ba567f00b/transformers-4.2.2-py3-none-any.whl (1.8MB)\n",
            "\u001b[K     |████████████████████████████████| 1.8MB 3.9MB/s \n",
            "\u001b[?25hCollecting python-telegram-bot>=13.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cc/b3/f363e9c5c2e4690a1fd352c01263eb2938952888c09d73c824b49d288dcc/python_telegram_bot-13.1-py3-none-any.whl (422kB)\n",
            "\u001b[K     |████████████████████████████████| 430kB 39.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.4.0->-r requirements.txt (line 1)) (0.10.0)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.4.0->-r requirements.txt (line 1)) (1.6.3)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.4.0->-r requirements.txt (line 1)) (0.3.3)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.4.0->-r requirements.txt (line 1)) (3.12.4)\n",
            "Requirement already satisfied: h5py~=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.4.0->-r requirements.txt (line 1)) (2.10.0)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.4.0->-r requirements.txt (line 1)) (1.1.0)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.4.0->-r requirements.txt (line 1)) (1.12.1)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.4.0->-r requirements.txt (line 1)) (1.15.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.4.0->-r requirements.txt (line 1)) (2.4.0)\n",
            "Requirement already satisfied: grpcio~=1.32.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.4.0->-r requirements.txt (line 1)) (1.32.0)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.4.0->-r requirements.txt (line 1)) (0.36.2)\n",
            "Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.4.0->-r requirements.txt (line 1)) (2.4.0)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.4.0->-r requirements.txt (line 1)) (1.1.2)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.4.0->-r requirements.txt (line 1)) (1.12)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.4.0->-r requirements.txt (line 1)) (3.7.4.3)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.4.0->-r requirements.txt (line 1)) (3.3.0)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.4.0->-r requirements.txt (line 1)) (0.2.0)\n",
            "Requirement already satisfied: numpy~=1.19.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.4.0->-r requirements.txt (line 1)) (1.19.5)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch>=1.7.0->-r requirements.txt (line 2)) (0.8)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.7.0->-r requirements.txt (line 2)) (0.16.0)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 38.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers>=4.2.2->-r requirements.txt (line 3)) (2019.12.20)\n",
            "Collecting tokenizers==0.9.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/1c/e789a8b12e28be5bc1ce2156cf87cb522b379be9cadc7ad8091a4cc107c4/tokenizers-0.9.4-cp36-cp36m-manylinux2010_x86_64.whl (2.9MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9MB 34.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from transformers>=4.2.2->-r requirements.txt (line 3)) (3.3.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers>=4.2.2->-r requirements.txt (line 3)) (3.0.12)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers>=4.2.2->-r requirements.txt (line 3)) (4.41.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers>=4.2.2->-r requirements.txt (line 3)) (20.8)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers>=4.2.2->-r requirements.txt (line 3)) (2.23.0)\n",
            "Requirement already satisfied: tornado>=5.1 in /usr/local/lib/python3.6/dist-packages (from python-telegram-bot>=13.1->-r requirements.txt (line 4)) (5.1.1)\n",
            "Collecting cryptography\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c9/de/7054df0620b5411ba45480f0261e1fb66a53f3db31b28e3aa52c026e72d9/cryptography-3.3.1-cp36-abi3-manylinux2010_x86_64.whl (2.6MB)\n",
            "\u001b[K     |████████████████████████████████| 2.6MB 32.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: pytz>=2018.6 in /usr/local/lib/python3.6/dist-packages (from python-telegram-bot>=13.1->-r requirements.txt (line 4)) (2018.9)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from python-telegram-bot>=13.1->-r requirements.txt (line 4)) (2020.12.5)\n",
            "Requirement already satisfied: decorator>=4.4.0 in /usr/local/lib/python3.6/dist-packages (from python-telegram-bot>=13.1->-r requirements.txt (line 4)) (4.4.2)\n",
            "Collecting APScheduler==3.6.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f3/34/9ef20ed473c4fd2c3df54ef77a27ae3fc7500b16b192add4720cab8b2c09/APScheduler-3.6.3-py2.py3-none-any.whl (58kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 7.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.9.2->tensorflow>=2.4.0->-r requirements.txt (line 1)) (51.3.3)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow>=2.4.0->-r requirements.txt (line 1)) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow>=2.4.0->-r requirements.txt (line 1)) (1.7.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow>=2.4.0->-r requirements.txt (line 1)) (3.3.3)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow>=2.4.0->-r requirements.txt (line 1)) (1.17.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow>=2.4.0->-r requirements.txt (line 1)) (0.4.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers>=4.2.2->-r requirements.txt (line 3)) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers>=4.2.2->-r requirements.txt (line 3)) (1.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers>=4.2.2->-r requirements.txt (line 3)) (3.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers>=4.2.2->-r requirements.txt (line 3)) (2.4.7)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers>=4.2.2->-r requirements.txt (line 3)) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers>=4.2.2->-r requirements.txt (line 3)) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers>=4.2.2->-r requirements.txt (line 3)) (2.10)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.6/dist-packages (from cryptography->python-telegram-bot>=13.1->-r requirements.txt (line 4)) (1.14.4)\n",
            "Requirement already satisfied: tzlocal>=1.2 in /usr/local/lib/python3.6/dist-packages (from APScheduler==3.6.3->python-telegram-bot>=13.1->-r requirements.txt (line 4)) (1.5.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.4.0->-r requirements.txt (line 1)) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.4.0->-r requirements.txt (line 1)) (4.2.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.4.0->-r requirements.txt (line 1)) (4.6)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow>=2.4.0->-r requirements.txt (line 1)) (1.3.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi>=1.12->cryptography->python-telegram-bot>=13.1->-r requirements.txt (line 4)) (2.20)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.4.0->-r requirements.txt (line 1)) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow>=2.4.0->-r requirements.txt (line 1)) (3.1.0)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893261 sha256=5e98248a1e960518f86ee52068bb347c8dd7c6bbcdbcb9a2e105b4774f4b6d41\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses, tokenizers, transformers, cryptography, APScheduler, python-telegram-bot\n",
            "Successfully installed APScheduler-3.6.3 cryptography-3.3.1 python-telegram-bot-13.1 sacremoses-0.0.43 tokenizers-0.9.4 transformers-4.2.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zY1PPfYRbG0j"
      },
      "source": [
        "Uncomment and run the following cell and restart the runtime if you get any warnings above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 704
        },
        "id": "u7_FYEt-a_GB",
        "outputId": "b0424867-3d81-4d3e-a675-ed4cd5396bbd"
      },
      "source": [
        "# !pip install -U ipykernel"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting ipykernel\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e1/92/8fec943b5b81078399f969f00557804d884c96fcd0bc296e81a2ed4fd270/ipykernel-5.1.3-py3-none-any.whl (116kB)\n",
            "\u001b[K     |████████████████████████████████| 122kB 8.4MB/s eta 0:00:01\n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: traitlets>=4.1.0 in /usr/local/lib/python3.6/dist-packages (from ipykernel) (4.3.3)\n",
            "Requirement already satisfied, skipping upgrade: tornado>=4.2 in /usr/local/lib/python3.6/dist-packages (from ipykernel) (6.0.3)\n",
            "Requirement already satisfied, skipping upgrade: jupyter-client in /usr/local/lib/python3.6/dist-packages (from ipykernel) (5.3.4)\n",
            "Requirement already satisfied, skipping upgrade: ipython>=5.0.0 in /usr/local/lib/python3.6/dist-packages (from ipykernel) (5.5.0)\n",
            "Requirement already satisfied, skipping upgrade: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.1.0->ipykernel) (0.2.0)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.1.0->ipykernel) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: decorator in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.1.0->ipykernel) (4.4.1)\n",
            "Requirement already satisfied, skipping upgrade: jupyter-core>=4.6.0 in /usr/local/lib/python3.6/dist-packages (from jupyter-client->ipykernel) (4.6.1)\n",
            "Requirement already satisfied, skipping upgrade: pyzmq>=13 in /usr/local/lib/python3.6/dist-packages (from jupyter-client->ipykernel) (17.0.0)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from jupyter-client->ipykernel) (2.6.1)\n",
            "Requirement already satisfied, skipping upgrade: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from ipython>=5.0.0->ipykernel) (1.0.18)\n",
            "Requirement already satisfied, skipping upgrade: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython>=5.0.0->ipykernel) (0.8.1)\n",
            "Requirement already satisfied, skipping upgrade: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython>=5.0.0->ipykernel) (4.7.0)\n",
            "Requirement already satisfied, skipping upgrade: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython>=5.0.0->ipykernel) (0.7.5)\n",
            "Requirement already satisfied, skipping upgrade: setuptools>=18.5 in /usr/local/lib/python3.6/dist-packages (from ipython>=5.0.0->ipykernel) (42.0.2)\n",
            "Requirement already satisfied, skipping upgrade: pygments in /usr/local/lib/python3.6/dist-packages (from ipython>=5.0.0->ipykernel) (2.1.3)\n",
            "Requirement already satisfied, skipping upgrade: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=5.0.0->ipykernel) (0.1.8)\n",
            "Requirement already satisfied, skipping upgrade: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->ipython>=5.0.0->ipykernel) (0.6.0)\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement ipykernel~=4.6.0, but you'll have ipykernel 5.1.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement tornado~=4.5.0, but you'll have tornado 6.0.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: ipykernel\n",
            "  Found existing installation: ipykernel 4.6.1\n",
            "    Uninstalling ipykernel-4.6.1:\n",
            "      Successfully uninstalled ipykernel-4.6.1\n",
            "Successfully installed ipykernel-5.1.3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "ipykernel"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9tGHgbNh4owO"
      },
      "source": [
        "Run a dialogue between two bots using the large DialogGPT on GPU."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rLu3lrHF4bS5",
        "outputId": "3addb4b5-c893-402e-e2a5-caf09137d783"
      },
      "source": [
        "!python run_bot.py --type=dialogue --config=configs/large-gpu.cfg"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;36mParsing the config...\u001b[0m\n",
            "\u001b[1;36mLoading the pipeline 'microsoft/DialoGPT-large'...\u001b[0m\n",
            "2021-01-25 14:11:02.669554: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
            "Downloading: 100% 642/642 [00:00<00:00, 528kB/s]\n",
            "Downloading: 100% 1.75G/1.75G [00:31<00:00, 55.1MB/s]\n",
            "Downloading: 100% 1.04M/1.04M [00:01<00:00, 941kB/s]\n",
            "Downloading: 100% 456k/456k [00:00<00:00, 506kB/s]\n",
            "First message: Ask me anything\n",
            "Number of turns: 10\n",
            "\u001b[1;36mRunning the dialogue...\u001b[0m\n",
            "Bot 1: Ask me anything\n",
            "Bot 1: Do you wear sunglasses when you play?\n",
            "Bot 2: What if you are the sun?\n",
            "Bot 1: Then you wear sunglasses when you're playing\n",
            "Bot 2: What if you wear a towel when you play?\n",
            "Bot 1: Then you shower in your towel when you shower.\n",
            "Bot 2: What if you shower in a towel towel?\n",
            "Bot 1: Then I shower in your towel towel.\n",
            "Bot 2: Is there any other way to shower?\n",
            "Bot 1: No, but you might be showering in the towel towel towel that you shower in shower.\n",
            "Bot 2: This has got to be the most beautiful shower.\n",
            "Bot 1: Well thank you, I do think that showering in towel towel towel is one of the most beautiful showers.\n",
            "Bot 2: It really is. And it's so beautiful you may actually shower in it, it does look lovely.\n",
            "Bot 1: Thank you. I appreciate you\n",
            "Bot 2: no problem. I'm glad you think so.\n",
            "Bot 1: That made me smile, thank you\n",
            "Bot 2: You're welcome. That was one of the best things I could have hoped for.You have no idea how lucky you are with that showering.\n",
            "Bot 1: Haha thanks. You are lucky too.\n",
            "Bot 2: You are very kind\n",
            "\n",
            "First message: Ask me anything\n",
            "Number of turns: 10\n",
            "\u001b[1;36mRunning the dialogue...\u001b[0m\n",
            "Bot 1: Ask me anything\n",
            "Bot 1: Do you enjoy your job?\n",
            "Bot 2: i'm very lazy\n",
            "Bot 1: Do you love it?\n",
            "Bot 2: I don't like it\n",
            "Bot 1: You shouldn't.\n",
            "Bot 2: Do you think that it's a problem?\n",
            "Bot 1: I think that if you hate it, it isn't the most comfortable.\n",
            "Bot 2: I can't argue that.\n",
            "Bot 1: ... Can I get some context? I'm a bit lost here.\n",
            "Bot 2: Me to\n",
            "Bot 1: Hue hue.\n",
            "Bot 2: Lets hug it out, kiddo.\n",
            "Bot 1: I'm glad, hehe.\n",
            "Bot 2: Why are you always like this? You're so happy.\n",
            "Bot 1: Its the happy place.\n",
            "Bot 2: And the happy place... and the happy place\n",
            "Bot 1: And the happy place.. And the happy place... And the happy place\n",
            "Bot 2: Don't let me get away!\n",
            "\n",
            "First message: Exception ignored in: <module 'threading' from '/usr/lib/python3.6/threading.py'>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.6/threading.py\", line 1279, in _shutdown\n",
            "    def _shutdown():\n",
            "KeyboardInterrupt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yS4rSjXUq9m-"
      },
      "source": [
        "Parse the config of the large DialoGPT and \"updown\" ranker on GPU."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8B7KHIGCw9c_",
        "outputId": "de6b9554-14f5-46fa-cbef-f61c70cde417"
      },
      "source": [
        "from gpt2bot.utils import parse_config\n",
        "\n",
        "config = parse_config('configs/large-updown-gpu.cfg')\n",
        "config"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;36mParsing the config...\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'chatbot_params': {'continue_after_restart': True,\n",
              "  'data_filename': 'bot_data.pkl',\n",
              "  'giphy_max_words': 3,\n",
              "  'giphy_prob': 0.1,\n",
              "  'giphy_token': 'YOUR_TOKEN_HERE',\n",
              "  'giphy_weirdness': 5,\n",
              "  'max_turns_history': 2,\n",
              "  'telegram_token': 'YOUR_TOKEN_HERE'},\n",
              " 'cond_ranker_weights': {'depth_weight': None,\n",
              "  'updown_weight': 1.0,\n",
              "  'width_weight': None},\n",
              " 'general_params': {'debug': False, 'device': 0, 'seed': None},\n",
              " 'generation_pipeline_kwargs': {'config': None,\n",
              "  'framework': None,\n",
              "  'model': 'microsoft/DialoGPT-large',\n",
              "  'tokenizer': None},\n",
              " 'generator_kwargs': {'bad_words_ids': None,\n",
              "  'bos_token_id': None,\n",
              "  'clean_up_tokenization_spaces': True,\n",
              "  'decoder_start_token_id': None,\n",
              "  'diversity_penalty': 0.0,\n",
              "  'do_sample': True,\n",
              "  'early_stopping': False,\n",
              "  'eos_token_id': None,\n",
              "  'length_penalty': 1.0,\n",
              "  'max_length': 1000,\n",
              "  'min_length': 1,\n",
              "  'no_repeat_ngram_size': 0,\n",
              "  'num_beam_groups': 1,\n",
              "  'num_beams': 1,\n",
              "  'num_return_sequences': 8,\n",
              "  'pad_token_id': None,\n",
              "  'repetition_penalty': 1.0,\n",
              "  'temperature': 1.0,\n",
              "  'top_k': 40,\n",
              "  'top_p': 0.9,\n",
              "  'use_cache': True},\n",
              " 'prior_ranker_weights': {'human_vs_machine_weight': None,\n",
              "  'human_vs_rand_weight': None}}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RmnarYPGTJQ2"
      },
      "source": [
        "config['chatbot_params']['telegram_token'] = 'YOUR_TOKEN_HERE'\n",
        "config['chatbot_params']['giphy_token'] = 'YOUR_TOKEN_HERE'"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5AcaOYfkh3dz",
        "outputId": "55140dd2-c8c8-4439-cc5e-169a8361642e"
      },
      "source": [
        "from gpt2bot.telegram_bot import TelegramBot\n",
        "\n",
        "TelegramBot(**config).run()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;36mLoading the pipeline 'microsoft/DialoGPT-large'...\u001b[0m\n",
            "\u001b[1;36mLoading the pipeline 'microsoft/DialogRPT-updown'...\u001b[0m\n",
            "\u001b[1;36mInitializing the telegram bot...\u001b[0m\n",
            "\u001b[1;36mRunning the telegram bot...\u001b[0m\n",
            "\u001b[38;21m447924619 - User: Ask me anything\u001b[0m\n",
            "\u001b[38;21m447924619 - Bot: Would you rather fight 10 duck sized horses or one horse sized duck?\u001b[0m\n",
            "\u001b[38;21m447924619 - User: I would go with 10 duck sized horses\u001b[0m\n",
            "\u001b[38;21m447924619 - Bot: Is it easy to get into?\u001b[0m\n",
            "\u001b[38;21m447924619 - User: Depends on how quickly you can run\u001b[0m\n",
            "\u001b[38;21m447924619 - Bot: I run faster than a duck.\u001b[0m\n",
            "\u001b[38;21m447924619 - User: You’re the lucky one\u001b[0m\n",
            "\u001b[38;21m447924619 - Bot: That's the first time I've heard that in a while...\u001b[0m\n",
            "\u001b[38;21m447924619 - User: Ask me anything\u001b[0m\n",
            "\u001b[38;21m447924619 - Bot: If you can get a decent job and a decent paycheque, is there a place to live where the rent is more expensive than the minimum wage?\u001b[0m\n",
            "\u001b[38;21m447924619 - User: California? I don’t know\u001b[0m\n",
            "\u001b[38;21m447924619 - Bot: Then you really shouldn't worry about it. You don't have to worry about this, this is a thread about things you don't really care about.\u001b[0m\n",
            "\u001b[38;21m447924619 - User: But I do care about it to be honest\u001b[0m\n",
            "\u001b[38;21m447924619 - Bot: Well if you really do not care about it, then you will be relieved when you get to work in the USA.\u001b[0m\n",
            "\u001b[38;21m447924619 - User: Thanks for your input\u001b[0m\n",
            "\u001b[38;21m447924619 - Bot: If you care about it, you don't have to worry about it.\u001b[0m\n",
            "\u001b[38;21m447924619 - User: Aight\u001b[0m\n",
            "\u001b[38;21m447924619 - Bot: Okay thank you\u001b[0m\n",
            "\u001b[33;21mlist indices must be integers or slices, not str\u001b[0m\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fBSolNDhsqrX"
      },
      "source": [
        "Go to your bot's Telegram channel, type /start and start conversation with the bot."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ULFoe0ljNbk"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}