{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Demo.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"c12qYj4FafMr","colab_type":"code","outputId":"5fe5242d-ace7-4db5-e31d-b1e4e816c951","executionInfo":{"status":"ok","timestamp":1578853658773,"user_tz":-60,"elapsed":8896,"user":{"displayName":"Oleg Polakow","photoUrl":"https://lh4.googleusercontent.com/-OxrfQHAWmSQ/AAAAAAAAAAI/AAAAAAAABR4/cis0IgU-Avs/s64/photo.jpg","userId":"08729449616485726726"}},"colab":{"base_uri":"https://localhost:8080/","height":631}},"source":["!pip install transformers==2.3.0"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Collecting transformers==2.3.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/50/10/aeefced99c8a59d828a92cc11d213e2743212d3641c87c82d61b035a7d5c/transformers-2.3.0-py3-none-any.whl (447kB)\n","\u001b[K     |████████████████████████████████| 450kB 2.7MB/s \n","\u001b[?25hRequirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers==2.3.0) (1.10.47)\n","Collecting sentencepiece\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/f4/2d5214cbf13d06e7cb2c20d84115ca25b53ea76fa1f0ade0e3c9749de214/sentencepiece-0.1.85-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n","\u001b[K     |████████████████████████████████| 1.0MB 54.7MB/s \n","\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from transformers==2.3.0) (4.28.1)\n","Collecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/b4/7a41d630547a4afd58143597d5a49e07bfd4c42914d8335b2a5657efc14b/sacremoses-0.0.38.tar.gz (860kB)\n","\u001b[K     |████████████████████████████████| 870kB 54.7MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers==2.3.0) (2019.12.20)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers==2.3.0) (2.21.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers==2.3.0) (1.17.5)\n","Requirement already satisfied: botocore<1.14.0,>=1.13.47 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers==2.3.0) (1.13.47)\n","Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers==2.3.0) (0.9.4)\n","Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers==2.3.0) (0.2.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.3.0) (1.12.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.3.0) (7.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.3.0) (0.14.1)\n","Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.3.0) (1.24.3)\n","Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.3.0) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.3.0) (2019.11.28)\n","Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.3.0) (2.8)\n","Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.47->boto3->transformers==2.3.0) (2.6.1)\n","Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.47->boto3->transformers==2.3.0) (0.15.2)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.38-cp36-none-any.whl size=884629 sha256=fad899dfc58124c9f434d892f114f4c86998b870cbba682ab1c33b502cbcd0d6\n","  Stored in directory: /root/.cache/pip/wheels/6d/ec/1a/21b8912e35e02741306f35f66c785f3afe94de754a0eaf1422\n","Successfully built sacremoses\n","Installing collected packages: sentencepiece, sacremoses, transformers\n","Successfully installed sacremoses-0.0.38 sentencepiece-0.1.85 transformers-2.3.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"AdfxKpnra5Cs","colab_type":"code","outputId":"bc7ef57b-4768-4584-d7ad-178df01ed9af","executionInfo":{"status":"ok","timestamp":1578853666539,"user_tz":-60,"elapsed":11623,"user":{"displayName":"Oleg Polakow","photoUrl":"https://lh4.googleusercontent.com/-OxrfQHAWmSQ/AAAAAAAAAAI/AAAAAAAABR4/cis0IgU-Avs/s64/photo.jpg","userId":"08729449616485726726"}},"colab":{"base_uri":"https://localhost:8080/","height":631}},"source":["!pip install python-telegram-bot --upgrade"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Collecting python-telegram-bot\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/11/8f/e1ae8acee0398c041464ceb97be4f76819876df8585660ee402e92015d44/python_telegram_bot-12.3.0-py2.py3-none-any.whl (351kB)\n","\r\u001b[K     |█                               | 10kB 25.1MB/s eta 0:00:01\r\u001b[K     |█▉                              | 20kB 1.7MB/s eta 0:00:01\r\u001b[K     |██▉                             | 30kB 2.5MB/s eta 0:00:01\r\u001b[K     |███▊                            | 40kB 1.7MB/s eta 0:00:01\r\u001b[K     |████▋                           | 51kB 2.1MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 61kB 2.5MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 71kB 2.9MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 81kB 3.3MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 92kB 3.7MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 102kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 112kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 122kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████                    | 133kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 143kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 153kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 163kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 174kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 184kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 194kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 204kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 215kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 225kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 235kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 245kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 256kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 266kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 276kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 286kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 296kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 307kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 317kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 327kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 337kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 348kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 358kB 2.8MB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: certifi in /usr/local/lib/python3.6/dist-packages (from python-telegram-bot) (2019.11.28)\n","Requirement already satisfied, skipping upgrade: future>=0.16.0 in /usr/local/lib/python3.6/dist-packages (from python-telegram-bot) (0.16.0)\n","Collecting tornado>=5.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/30/78/2d2823598496127b21423baffaa186b668f73cd91887fcef78b6eade136b/tornado-6.0.3.tar.gz (482kB)\n","\u001b[K     |████████████████████████████████| 491kB 59.2MB/s \n","\u001b[?25hCollecting cryptography\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ca/9a/7cece52c46546e214e10811b36b2da52ce1ea7fa203203a629b8dfadad53/cryptography-2.8-cp34-abi3-manylinux2010_x86_64.whl (2.3MB)\n","\u001b[K     |████████████████████████████████| 2.3MB 43.4MB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: six>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from cryptography->python-telegram-bot) (1.12.0)\n","Requirement already satisfied, skipping upgrade: cffi!=1.11.3,>=1.8 in /usr/local/lib/python3.6/dist-packages (from cryptography->python-telegram-bot) (1.13.2)\n","Requirement already satisfied, skipping upgrade: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi!=1.11.3,>=1.8->cryptography->python-telegram-bot) (2.19)\n","Building wheels for collected packages: tornado\n","  Building wheel for tornado (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for tornado: filename=tornado-6.0.3-cp36-cp36m-linux_x86_64.whl size=423192 sha256=2120035c7feb28b5bebf50c13f79ffb7abaa93fff032c1f1ee84d3766de1a53c\n","  Stored in directory: /root/.cache/pip/wheels/84/bf/40/2f6ef700f48401ca40e5e3dd7d0e3c0a90e064897b7fe5fc08\n","Successfully built tornado\n","\u001b[31mERROR: google-colab 1.0.0 has requirement tornado~=4.5.0, but you'll have tornado 6.0.3 which is incompatible.\u001b[0m\n","Installing collected packages: tornado, cryptography, python-telegram-bot\n","  Found existing installation: tornado 4.5.3\n","    Uninstalling tornado-4.5.3:\n","      Successfully uninstalled tornado-4.5.3\n","Successfully installed cryptography-2.8 python-telegram-bot-12.3.0 tornado-6.0.3\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["tornado"]}}},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"zY1PPfYRbG0j","colab_type":"text"},"source":["Run the following cell and restart the runtime if you get any warnings above."]},{"cell_type":"code","metadata":{"id":"u7_FYEt-a_GB","colab_type":"code","outputId":"f6be7dca-321f-42e4-f949-e37ec3c7ef1c","executionInfo":{"status":"ok","timestamp":1578853679273,"user_tz":-60,"elapsed":22973,"user":{"displayName":"Oleg Polakow","photoUrl":"https://lh4.googleusercontent.com/-OxrfQHAWmSQ/AAAAAAAAAAI/AAAAAAAABR4/cis0IgU-Avs/s64/photo.jpg","userId":"08729449616485726726"}},"colab":{"base_uri":"https://localhost:8080/","height":704}},"source":["!pip install -U ipykernel"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Collecting ipykernel\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e1/92/8fec943b5b81078399f969f00557804d884c96fcd0bc296e81a2ed4fd270/ipykernel-5.1.3-py3-none-any.whl (116kB)\n","\r\u001b[K     |██▉                             | 10kB 29.8MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 20kB 1.7MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 30kB 2.5MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 40kB 1.6MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 51kB 2.0MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 61kB 2.4MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 71kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 81kB 3.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 92kB 3.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 102kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 112kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 122kB 2.7MB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: ipython>=5.0.0 in /usr/local/lib/python3.6/dist-packages (from ipykernel) (5.5.0)\n","Requirement already satisfied, skipping upgrade: tornado>=4.2 in /usr/local/lib/python3.6/dist-packages (from ipykernel) (6.0.3)\n","Requirement already satisfied, skipping upgrade: traitlets>=4.1.0 in /usr/local/lib/python3.6/dist-packages (from ipykernel) (4.3.3)\n","Requirement already satisfied, skipping upgrade: jupyter-client in /usr/local/lib/python3.6/dist-packages (from ipykernel) (5.3.4)\n","Requirement already satisfied, skipping upgrade: setuptools>=18.5 in /usr/local/lib/python3.6/dist-packages (from ipython>=5.0.0->ipykernel) (42.0.2)\n","Requirement already satisfied, skipping upgrade: pygments in /usr/local/lib/python3.6/dist-packages (from ipython>=5.0.0->ipykernel) (2.1.3)\n","Requirement already satisfied, skipping upgrade: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython>=5.0.0->ipykernel) (4.7.0)\n","Requirement already satisfied, skipping upgrade: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from ipython>=5.0.0->ipykernel) (1.0.18)\n","Requirement already satisfied, skipping upgrade: decorator in /usr/local/lib/python3.6/dist-packages (from ipython>=5.0.0->ipykernel) (4.4.1)\n","Requirement already satisfied, skipping upgrade: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython>=5.0.0->ipykernel) (0.7.5)\n","Requirement already satisfied, skipping upgrade: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython>=5.0.0->ipykernel) (0.8.1)\n","Requirement already satisfied, skipping upgrade: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.1.0->ipykernel) (0.2.0)\n","Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.1.0->ipykernel) (1.12.0)\n","Requirement already satisfied, skipping upgrade: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from jupyter-client->ipykernel) (2.6.1)\n","Requirement already satisfied, skipping upgrade: jupyter-core>=4.6.0 in /usr/local/lib/python3.6/dist-packages (from jupyter-client->ipykernel) (4.6.1)\n","Requirement already satisfied, skipping upgrade: pyzmq>=13 in /usr/local/lib/python3.6/dist-packages (from jupyter-client->ipykernel) (17.0.0)\n","Requirement already satisfied, skipping upgrade: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->ipython>=5.0.0->ipykernel) (0.6.0)\n","Requirement already satisfied, skipping upgrade: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=5.0.0->ipykernel) (0.1.8)\n","\u001b[31mERROR: google-colab 1.0.0 has requirement ipykernel~=4.6.0, but you'll have ipykernel 5.1.3 which is incompatible.\u001b[0m\n","\u001b[31mERROR: google-colab 1.0.0 has requirement tornado~=4.5.0, but you'll have tornado 6.0.3 which is incompatible.\u001b[0m\n","Installing collected packages: ipykernel\n","  Found existing installation: ipykernel 4.6.1\n","    Uninstalling ipykernel-4.6.1:\n","      Successfully uninstalled ipykernel-4.6.1\n","Successfully installed ipykernel-5.1.3\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["ipykernel"]}}},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"mjvt2nJfZntK","colab_type":"code","outputId":"ef3d326f-ebf0-4afb-828a-c072750e7b1a","executionInfo":{"status":"ok","timestamp":1578853741261,"user_tz":-60,"elapsed":6367,"user":{"displayName":"Oleg Polakow","photoUrl":"https://lh4.googleusercontent.com/-OxrfQHAWmSQ/AAAAAAAAAAI/AAAAAAAABR4/cis0IgU-Avs/s64/photo.jpg","userId":"08729449616485726726"}},"colab":{"base_uri":"https://localhost:8080/","height":143}},"source":["!git clone https://github.com/polakowo/textai.git"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Cloning into 'textai'...\n","remote: Enumerating objects: 352, done.\u001b[K\n","remote: Counting objects: 100% (352/352), done.\u001b[K\n","remote: Compressing objects: 100% (252/252), done.\u001b[K\n","remote: Total 792 (delta 171), reused 234 (delta 83), pack-reused 440\u001b[K\n","Receiving objects: 100% (792/792), 10.74 MiB | 7.20 MiB/s, done.\n","Resolving deltas: 100% (330/330), done.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"8ZtcFlgvazng","colab_type":"code","outputId":"3671ba40-3ca3-44ed-aa74-d3c2ed1f48ce","executionInfo":{"status":"ok","timestamp":1578853743741,"user_tz":-60,"elapsed":8324,"user":{"displayName":"Oleg Polakow","photoUrl":"https://lh4.googleusercontent.com/-OxrfQHAWmSQ/AAAAAAAAAAI/AAAAAAAABR4/cis0IgU-Avs/s64/photo.jpg","userId":"08729449616485726726"}},"colab":{"base_uri":"https://localhost:8080/","height":53}},"source":["!ls textai/GPT2Bot"],"execution_count":8,"outputs":[{"output_type":"stream","text":["chatbot.cfg  Demo.ipynb   interactive_bot.py  README.md\n","decoder.py   __init__.py  model.py\t      telegram_bot.py\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"iM774HIQbejL","colab_type":"code","outputId":"4ea4847b-cc54-425b-b21c-e2e13514da13","executionInfo":{"status":"ok","timestamp":1578853745828,"user_tz":-60,"elapsed":9915,"user":{"displayName":"Oleg Polakow","photoUrl":"https://lh4.googleusercontent.com/-OxrfQHAWmSQ/AAAAAAAAAAI/AAAAAAAABR4/cis0IgU-Avs/s64/photo.jpg","userId":"08729449616485726726"}},"colab":{"base_uri":"https://localhost:8080/","height":827}},"source":["!cat textai/GPT2Bot/chatbot.cfg"],"execution_count":9,"outputs":[{"output_type":"stream","text":["[model]\n","# Path to folder where the model files will be stored.\n","data_folder = models\n","# Size of the GPT-2 model. Could be one of 'small' (117M), 'medium' (345M) or 'large' (1542M).\n","# Select small for CPU or experimentation, and medium for GPU\n","model_size = medium\n","# Dataset name the model was trained on. One of 'multiref' (147M multi-turn dialogue \n","# from Reddit discussion thread) or 'dstc' (DSTC-7 grounded dialogue generation challenge).\n","dataset = multiref\n","# True: load model trained from scratch or False: load model trained from fine-tuning the GPT-2.\n","from_scratch = False\n","# Avoid using CUDA when available.\n","no_cuda = False\n","\n","[decoder]\n","# Seed for random number generators, fix seed to reproduce results.\n","# By default there is no seed and each turn should be unique.\n","seed\n","# The number of turns the model should consider. \n","# Set to 0 to focus on the last message. Set to -1 for unlimited context length.\n","temperature = 0.7\n","# Integer value controlling diversity. 1 means only 1 word is\n","# considered for each step (token), resulting in deterministic completions,\n","# while 40 means 40 words are considered at each step. 0 (default) is a\n","# special setting meaning no restrictions. 40 generally is a good value.\n","top_k = 40\n","# Like top_k, top_p is a constraint on the craziness of the output\n","top_p = 0.9\n","# Length of text to be returned, inclusive of punctuations etc.\n","length = 32\n","# Number of samples to return\n","num_samples = 1\n","\n","[chatbot]\n","# Float value controlling randomness in boltzmann\n","# distribution. Lower temperature results in less random completions. As the\n","# temperature approaches zero, the model will become deterministic and\n","# repetitive. Higher temperature results in more random completions.\n","turns_memory = 2\n","# Your Telegram token. See https://core.telegram.org/bots\n","telegram_token = *YOUR_TOKEN_HERE*\n","# Your GIPHY API token. See \n","giphy_token = *YOUR_TOKEN_HERE*\n","# Value from 0-10 which makes results weirder as you go up the scale.\n","giphy_weirdness = 5"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"CXsTgp27q0Rx","colab_type":"text"},"source":["Change the config file how you like."]},{"cell_type":"code","metadata":{"id":"_4_7cTmaavIg","colab_type":"code","colab":{}},"source":["import configparser\n","\n","config = configparser.ConfigParser(allow_no_value=True)\n","config.read('textai/GPT2Bot/chatbot.cfg')\n","config.set('decoder', 'seed', '42') # reproducible results\n","config.set('decoder', 'top_k', '1') # test greedy sampling\n","\n","with open('textai/GPT2Bot/my_chatbot.cfg', 'w') as f:\n","    config.write(f)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"U1706pocb5eZ","colab_type":"code","outputId":"a050461f-6f23-4adb-fad2-bc61f34d7e7e","executionInfo":{"status":"ok","timestamp":1578853757806,"user_tz":-60,"elapsed":3608,"user":{"displayName":"Oleg Polakow","photoUrl":"https://lh4.googleusercontent.com/-OxrfQHAWmSQ/AAAAAAAAAAI/AAAAAAAABR4/cis0IgU-Avs/s64/photo.jpg","userId":"08729449616485726726"}},"colab":{"base_uri":"https://localhost:8080/","height":395}},"source":["!cat textai/GPT2Bot/my_chatbot.cfg"],"execution_count":11,"outputs":[{"output_type":"stream","text":["[model]\n","data_folder = models\n","model_size = medium\n","dataset = multiref\n","from_scratch = False\n","no_cuda = False\n","\n","[decoder]\n","seed = 42\n","temperature = 0.7\n","top_k = 1\n","top_p = 0.9\n","length = 32\n","num_samples = 1\n","\n","[chatbot]\n","turns_memory = 2\n","telegram_token = *YOUR_TOKEN_HERE*\n","giphy_token = *YOUR_TOKEN_HERE*\n","giphy_weirdness = 5\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"z5xTyqGdnh1d","colab_type":"code","outputId":"cb58ad3f-00f5-404c-8f95-7030b04da5ed","executionInfo":{"status":"ok","timestamp":1578838337550,"user_tz":-60,"elapsed":4490,"user":{"displayName":"Oleg Polakow","photoUrl":"https://lh4.googleusercontent.com/-OxrfQHAWmSQ/AAAAAAAAAAI/AAAAAAAABR4/cis0IgU-Avs/s64/photo.jpg","userId":"08729449616485726726"}},"colab":{"base_uri":"https://localhost:8080/","height":323}},"source":["!nvidia-smi"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Sun Jan 12 14:12:14 2020       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 440.44       Driver Version: 418.67       CUDA Version: 10.1     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   43C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                       GPU Memory |\n","|  GPU       PID   Type   Process name                             Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"638dKOn7q8Bx","colab_type":"text"},"source":["Run the interactive chatbot."]},{"cell_type":"code","metadata":{"id":"lgwI4QdUcP6X","colab_type":"code","outputId":"4d7dabfe-59df-48dd-c993-638d56ae08f2","executionInfo":{"status":"ok","timestamp":1578824439707,"user_tz":-60,"elapsed":202068,"user":{"displayName":"Oleg Polakow","photoUrl":"https://lh4.googleusercontent.com/-OxrfQHAWmSQ/AAAAAAAAAAI/AAAAAAAABR4/cis0IgU-Avs/s64/photo.jpg","userId":"08729449616485726726"}},"colab":{"base_uri":"https://localhost:8080/","height":413}},"source":["!python textai/GPT2Bot/interactive_bot.py --config textai/GPT2Bot/my_chatbot.cfg"],"execution_count":0,"outputs":[{"output_type":"stream","text":["2020-01-12 10:17:24,310 - model - INFO - Downloading model files...\n","100% 293/293 [00:00<00:00, 255495.03B/s]\n","100% 1042301/1042301 [00:00<00:00, 1438618.54B/s]\n","100% 456318/456318 [00:00<00:00, 1029685.64B/s]\n","100% 862954531/862954531 [01:02<00:00, 13843572.90B/s]\n","2020-01-12 10:18:30,918 - model - INFO - Loading the model...\n","2020-01-12 10:18:51,085 - __main__ - INFO - Running the chatbot...\n","User >>> Hello!\n","Bot >>> Hello! :D\n","User >>> How was your day?\n","Bot >>> It was okay.\n","User >>> Did you enjoy the weather today?\n","Bot >>> It was nice.\n","User >>> Where are you from?\n","Bot >>> I'm from the Netherlands.\n","User >>> Which city?\n","Bot >>> I'm from Amsterdam.\n","User >>> Is pot legal in Amsterdam?\n","Bot >>> It is.\n","User >>> Sounds fun.\n","Bot >>> It is.\n","User >>> /quit\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"yS4rSjXUq9m-","colab_type":"text"},"source":["Run the Telegram bot."]},{"cell_type":"code","metadata":{"id":"RmnarYPGTJQ2","colab_type":"code","colab":{}},"source":["config = configparser.ConfigParser(allow_no_value=True)\n","config.read('textai/GPT2Bot/chatbot.cfg')\n","config.set('decoder', 'seed', '42')\n","config.set('chatbot', 'telegram_token', '*YOUR_TOKEN_HERE*')\n","config.set('chatbot', 'giphy_token', '*YOUR_TOKEN_HERE*')\n","\n","with open('textai/GPT2Bot/my_chatbot.cfg', 'w') as f:\n","    config.write(f)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"de-g5_AUTQZ_","colab_type":"code","outputId":"8b733284-b39d-494c-8195-46523e9131e1","executionInfo":{"status":"ok","timestamp":1578862448469,"user_tz":-60,"elapsed":2392,"user":{"displayName":"Oleg Polakow","photoUrl":"https://lh4.googleusercontent.com/-OxrfQHAWmSQ/AAAAAAAAAAI/AAAAAAAABR4/cis0IgU-Avs/s64/photo.jpg","userId":"08729449616485726726"}},"colab":{"base_uri":"https://localhost:8080/","height":395}},"source":["!cat textai/GPT2Bot/my_chatbot.cfg"],"execution_count":59,"outputs":[{"output_type":"stream","text":["[model]\n","data_folder = models\n","model_size = medium\n","dataset = multiref\n","from_scratch = False\n","no_cuda = False\n","\n","[decoder]\n","seed = 42\n","temperature = 0.7\n","top_k = 40\n","top_p = 0.9\n","length = 32\n","num_samples = 1\n","\n","[chatbot]\n","turns_memory = 2\n","telegram_token = *YOUR_TOKEN_HERE*\n","giphy_token = *YOUR_TOKEN_HERE*\n","giphy_weirdness = 5\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5AcaOYfkh3dz","colab_type":"code","outputId":"d044a333-0598-4f5a-fe2f-1d5d0d70585f","executionInfo":{"status":"ok","timestamp":1578862443250,"user_tz":-60,"elapsed":642354,"user":{"displayName":"Oleg Polakow","photoUrl":"https://lh4.googleusercontent.com/-OxrfQHAWmSQ/AAAAAAAAAAI/AAAAAAAABR4/cis0IgU-Avs/s64/photo.jpg","userId":"08729449616485726726"}},"colab":{"base_uri":"https://localhost:8080/","height":143}},"source":["!python textai/GPT2Bot/telegram_bot.py --config textai/GPT2Bot/my_chatbot.cfg"],"execution_count":57,"outputs":[{"output_type":"stream","text":["2020-01-12 20:43:24,962 - model - INFO - Downloading model files...\n","2020-01-12 20:43:24,962 - model - INFO - Loading the model...\n","2020-01-12 20:43:38,591 - __main__ - INFO - Initializing the bot...\n","2020-01-12 20:43:38,592 - __main__ - INFO - Running the chatbot...\n","2020-01-12 20:53:39,358 - telegram.ext.updater - INFO - Received signal 2 (SIGINT), stopping...\n","2020-01-12 20:53:39,358 - telegram.ext.updater - INFO - Received signal 2 (SIGINT), stopping...\n","^C\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"fBSolNDhsqrX","colab_type":"text"},"source":["Go to your bot's Telegram channel, type /start and start conversation with the bot."]},{"cell_type":"code","metadata":{"id":"3ULFoe0ljNbk","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}